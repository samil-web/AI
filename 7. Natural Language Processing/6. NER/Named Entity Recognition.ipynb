{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# NLP Lecture @ Strive School - 21st July 2021\r\n",
    "# NER update\r\n",
    "\r\n",
    "'''\r\n",
    "Since today we are exploring the world of natural language processing, we’ll deepen in the Named Entity Recognition technique: this is just one of the mechanisms that NLP embodies. The recognition of named entities as the process of automatic identification of the entities present in a text and consequent classification into predefined categories such as \"person\", \"organization\", \"position\" is a quite common activity and expect for English, trained models with spaCy offer few labels that could be improved through training.\r\n",
    "\r\n",
    "Following the case study of this morning, try to emulate it in order to label all the brands present in the provided datasets, choosing the one you prefer OR trying to label all them and to train the model to recognize new different entities. The result should be twofold: the final model should be able to recognize brands that it has already seen, but already new ones.\r\n",
    "The brands proposed in the dataset concern fashion, cars and food.\r\n",
    "In order to test the accuracy of the model, test it with sentences and brands the model has never seen.\r\n",
    "\r\n",
    "Sample of the dataset\r\n",
    "---------------------\r\n",
    "- Cate Blanchett in Armani Privé. Rating: 8. Concludes as a rare butterfly, or from Rorschach's Test, or from computerized axial tomography.\r\n",
    "- I liked everything, recommend it! Another quality Xiaomi product...\r\n",
    "- What is the price of that Fiat 500XL?\r\n",
    "\r\n",
    "Info:\r\n",
    "- Feel free to change or arrange a new dataset\r\n",
    "- Try experimenting and tuning with the hyperparameters\r\n",
    "- Feel free to use or change the code you've seen during the morning session\r\n",
    "- TBD = To be done (from you!) :)\r\n",
    "\r\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nSince today we are exploring the world of natural language processing, we’ll deepen in the Named Entity Recognition technique: this is just one of the mechanisms that NLP embodies. The recognition of named entities as the process of automatic identification of the entities present in a text and consequent classification into predefined categories such as \"person\", \"organization\", \"position\" is a quite common activity and expect for English, trained models with spaCy offer few labels that could be improved through training.\\n\\nFollowing the case study of this morning, try to emulate it in order to label all the brands present in the provided datasets, choosing the one you prefer OR trying to label all them and to train the model to recognize new different entities. The result should be twofold: the final model should be able to recognize brands that it has already seen, but already new ones.\\nThe brands proposed in the dataset concern fashion, cars and food.\\nIn order to test the accuracy of the model, test it with sentences and brands the model has never seen.\\n\\nSample of the dataset\\n---------------------\\n- Cate Blanchett in Armani Privé. Rating: 8. Concludes as a rare butterfly, or from Rorschach\\'s Test, or from computerized axial tomography.\\n- I liked everything, recommend it! Another quality Xiaomi product...\\n- What is the price of that Fiat 500XL?\\n\\nInfo:\\n- Feel free to change or arrange a new dataset\\n- Try experimenting and tuning with the hyperparameters\\n- Feel free to use or change the code you\\'ve seen during the morning session\\n- TBD = To be done (from you!) :)\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# STEP 0 - PRE REQUISITES\r\n",
    "\r\n",
    "# python -m spacy download en_core_web_lg\r\n",
    "\r\n",
    "# TBD: Import libraries\r\n",
    "import spacy\r\n",
    "import random\r\n",
    "from spacy.util import minibatch, compounding\r\n",
    "from pathlib import Path\r\n",
    "from spacy.training import Example\r\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\r\n",
    "\r\n",
    "nlp = spacy.load('en_core_web_lg')\r\n",
    "# TBD: Load preferred model\r\n",
    "print(nlp)\r\n",
    "with open(\"food.txt\") as file:\r\n",
    "    dataset = file.read()\r\n",
    "\r\n",
    "# TBD: Load the dataset and test it as-is\r\n",
    "doc = nlp(dataset)\r\n",
    "print('Entities:',[(ent.text,ent.label_) for ent in doc.ents])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<spacy.lang.en.English object at 0x000001EF84826910>\n",
      "Entities: [('Italian', 'NORP'), ('first', 'ORDINAL'), ('Arrosticini', 'PERSON'), ('Alfredo', 'PERSON'), ('Naples', 'GPE'), ('Zaza', 'PERSON'), ('ApplePie', 'ORG'), ('Bologna', 'GPE'), ('Fiorentina Steak', 'PERSON'), ('Pineapple', 'ORG'), ('First', 'ORDINAL'), ('Bronte', 'PERSON'), ('Coca-cola', 'ORG'), ('Fanta', 'ORG'), ('Pepsi', 'ORG'), ('One', 'CARDINAL'), ('Sorrento', 'GPE'), ('Coffee\\nBread', 'ORG'), ('Love', 'WORK_OF_ART'), ('Fatte', 'PERSON'), ('vedrai che il mondo poi ti', 'PERSON'), ('Pastiera', 'PERSON'), ('the United States', 'GPE'), ('Two', 'CARDINAL'), ('two', 'CARDINAL'), ('24 hours', 'TIME'), ('24', 'CARDINAL'), ('two hours', 'TIME')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# STEP 1 - TRAIN DATA\r\n",
    "\r\n",
    "# Prepare training data\r\n",
    "\r\n",
    "# TBD: define all the entities by extracting the words and their indexes from the dataset\r\n",
    "# expected format is the following:  (\"sentence\", {\"entities\": [0,10, \"FOOD\"]})\r\n",
    "# STEP 0 - PRE REQUISITES\r\n",
    "\r\n",
    "# python -m spacy download en_core_web_lg\r\n",
    "\r\n",
    "# TBD: Import libraries\r\n",
    "import os \r\n",
    "import spacy\r\n",
    "import random\r\n",
    "from spacy.util import minibatch, compounding\r\n",
    "from pathlib import Path\r\n",
    "from spacy.training import Example\r\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\r\n",
    "\r\n",
    "nlp = spacy.load('en_core_web_lg')\r\n",
    "# TBD: Load preferred model\r\n",
    "print(nlp)\r\n",
    "with open(\"food.txt\") as file:\r\n",
    "    dataset = file.read()\r\n",
    "\r\n",
    "# TBD: Load the dataset and test it as-is\r\n",
    "doc = nlp(dataset)\r\n",
    "print('Entities:',[(ent.text,ent.label_) for ent in doc.ents])\r\n",
    "\r\n",
    "\r\n",
    "words = ['ketchup','pasta','carrot','pizza',\r\n",
    "        'garlic','tomato sauce','basil','carbonara',\r\n",
    "        'eggs','cheek fat','pancakes','parmigiana','eggplant',\r\n",
    "        'fettucine','heavy cream','polenta','risotto','espresso', \r\n",
    "        'arrosticini','spaghetti','fiorentina steak','pecorino',\r\n",
    "        'maccherone','nutella','amaro','pistachio','coca-cola', \r\n",
    "        'wine','pastiera','watermelon','cappucino','ice cream',\r\n",
    "        'soup','Lemon','chocolate','pineapple']\r\n",
    "\r\n",
    "train_data = []\r\n",
    "\r\n",
    "with open('food.txt') as file:\r\n",
    "    dataset = file.readlines()\r\n",
    "    for sentence in dataset:\r\n",
    "        print('######')\r\n",
    "        print('sentence: ',sentence)\r\n",
    "        print('######')\r\n",
    "        sentence = sentence.lower()\r\n",
    "        entities = []\r\n",
    "        for word in words:\r\n",
    "            word = word.lower()\r\n",
    "            if word in sentence:\r\n",
    "                start_index = sentence.index(word)\r\n",
    "                end_index = len(word) + start_index\r\n",
    "                print('word: ',word)\r\n",
    "                print('start index:',start_index)\r\n",
    "                print('end_index:',end_index)\r\n",
    "                pos = (start_index,end_index,'FOOD')\r\n",
    "                entities.append(pos)\r\n",
    "                print(entities)\r\n",
    "        element = (sentence.rstrip('\\n'),{'entities':entities})\r\n",
    "\r\n",
    "        train_data.append(element)\r\n",
    "        print('---------')\r\n",
    "        print('element:',element)\r\n",
    "\r\n",
    "        #('this is my sentence:',{'entities':[0,4,'PREP']})\r\n",
    "        # ('this is my sentence:',{'entities':[6,8,'VERB']})\r\n",
    "# STEP 2 - UPDATE MODEL\r\n",
    "\r\n",
    "ner = nlp.get_pipe('ner')\r\n",
    "\r\n",
    "for _,annotations in train_data:\r\n",
    "    # print('Annotation',annotations)\r\n",
    "    for ent in annotations.get('entities'):\r\n",
    "        # print(ent)\r\n",
    "        ner.add_label(ent[2])\r\n",
    "        \r\n",
    "        \r\n",
    "# TBD: load the needed pipeline\r\n",
    "\r\n",
    "# TBD: define the annotations\r\n",
    "\r\n",
    "# TBD: train the model\r\n",
    "\r\n",
    "\r\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\r\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\r\n",
    "\r\n",
    "# TBD: define the number of iterations, the batch size and the drop according to your experience or using an empirical value\r\n",
    "# Train model\r\n",
    "with nlp.disable_pipes(*unaffected_pipes):\r\n",
    "    for iteration in range(10):\r\n",
    "        print(\"Iteration #\" + str(iteration))\r\n",
    "\r\n",
    "        # Data shuffle for each iteration\r\n",
    "        random.shuffle(train_data)\r\n",
    "        losses = {}\r\n",
    "        batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\r\n",
    "        for batch in spacy.util.minibatch(train_data, size=3):\r\n",
    "            for text, annotations in batch:\r\n",
    "                # Create an Example object\r\n",
    "                doc = nlp.make_doc(text)\r\n",
    "                example = Example.from_dict(doc, annotations)\r\n",
    "                # Update the model\r\n",
    "                nlp.update([example], losses=losses, drop=0)\r\n",
    "        print(\"Losses:\", losses)\r\n",
    "\r\n",
    "# Save the model\r\n",
    "output_dir = Path('/ner/')\r\n",
    "nlp.to_disk(output_dir)\r\n",
    "print('Saved correctly')\r\n",
    "# TBD:\r\n",
    "# STEP 3 - TEST THE UPDATED MODEL\r\n",
    "print('Loading model....')\r\n",
    "# Load updated model\r\n",
    "nlp_updated = spacy.load(output_dir)\r\n",
    "\r\n",
    "doc =nlp_updated(\"I don't like pizza with pineapple.\")\r\n",
    "# TBD: test with a old sentence\r\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])\r\n",
    "\r\n",
    "# TBD: test with a new sentence and an old brand\r\n",
    "doc =nlp_updated(\"in carbonara, parmigiano is not used.\")\r\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])\r\n",
    "# TBD: test with a new sentence and a new brand\r\n",
    "doc =nlp_updated(\"Fabio likes full-stack development\")\r\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "######\n",
      "sentence:  Give me carrot cake.\n",
      "\n",
      "######\n",
      "word:  carrot\n",
      "start index: 8\n",
      "end_index: 14\n",
      "[(8, 14, 'FOOD')]\n",
      "---------\n",
      "element: ('give me carrot cake.', {'entities': [(8, 14, 'FOOD')]})\n",
      "######\n",
      "sentence:  I love simple pizza margherita with tomato sauce and mozzarella.\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 14\n",
      "end_index: 19\n",
      "[(14, 19, 'FOOD')]\n",
      "word:  tomato sauce\n",
      "start index: 36\n",
      "end_index: 48\n",
      "[(14, 19, 'FOOD'), (36, 48, 'FOOD')]\n",
      "---------\n",
      "element: ('i love simple pizza margherita with tomato sauce and mozzarella.', {'entities': [(14, 19, 'FOOD'), (36, 48, 'FOOD')]})\n",
      "######\n",
      "sentence:  I don't like pizza with garlic!\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 13\n",
      "end_index: 18\n",
      "[(13, 18, 'FOOD')]\n",
      "word:  garlic\n",
      "start index: 24\n",
      "end_index: 30\n",
      "[(13, 18, 'FOOD'), (24, 30, 'FOOD')]\n",
      "---------\n",
      "element: (\"i don't like pizza with garlic!\", {'entities': [(13, 18, 'FOOD'), (24, 30, 'FOOD')]})\n",
      "######\n",
      "sentence:  I like pasta with homemade tomato sauce and basil.\n",
      "\n",
      "######\n",
      "word:  pasta\n",
      "start index: 7\n",
      "end_index: 12\n",
      "[(7, 12, 'FOOD')]\n",
      "word:  tomato sauce\n",
      "start index: 27\n",
      "end_index: 39\n",
      "[(7, 12, 'FOOD'), (27, 39, 'FOOD')]\n",
      "word:  basil\n",
      "start index: 44\n",
      "end_index: 49\n",
      "[(7, 12, 'FOOD'), (27, 39, 'FOOD'), (44, 49, 'FOOD')]\n",
      "---------\n",
      "element: ('i like pasta with homemade tomato sauce and basil.', {'entities': [(7, 12, 'FOOD'), (27, 39, 'FOOD'), (44, 49, 'FOOD')]})\n",
      "######\n",
      "sentence:  Always make carbonara with eggs and cheek lard!\n",
      "\n",
      "######\n",
      "word:  carbonara\n",
      "start index: 12\n",
      "end_index: 21\n",
      "[(12, 21, 'FOOD')]\n",
      "word:  eggs\n",
      "start index: 27\n",
      "end_index: 31\n",
      "[(12, 21, 'FOOD'), (27, 31, 'FOOD')]\n",
      "---------\n",
      "element: ('always make carbonara with eggs and cheek lard!', {'entities': [(12, 21, 'FOOD'), (27, 31, 'FOOD')]})\n",
      "######\n",
      "sentence:  Don't mess with my carbonara!\n",
      "\n",
      "######\n",
      "word:  carbonara\n",
      "start index: 19\n",
      "end_index: 28\n",
      "[(19, 28, 'FOOD')]\n",
      "---------\n",
      "element: (\"don't mess with my carbonara!\", {'entities': [(19, 28, 'FOOD')]})\n",
      "######\n",
      "sentence:  Get your hands off my pancakes!\n",
      "\n",
      "######\n",
      "word:  pancakes\n",
      "start index: 22\n",
      "end_index: 30\n",
      "[(22, 30, 'FOOD')]\n",
      "---------\n",
      "element: ('get your hands off my pancakes!', {'entities': [(22, 30, 'FOOD')]})\n",
      "######\n",
      "sentence:  The original Italian \"parmigiana\" is done with eggplant, not zucchini.\n",
      "\n",
      "######\n",
      "word:  parmigiana\n",
      "start index: 22\n",
      "end_index: 32\n",
      "[(22, 32, 'FOOD')]\n",
      "word:  eggplant\n",
      "start index: 47\n",
      "end_index: 55\n",
      "[(22, 32, 'FOOD'), (47, 55, 'FOOD')]\n",
      "---------\n",
      "element: ('the original italian \"parmigiana\" is done with eggplant, not zucchini.', {'entities': [(22, 32, 'FOOD'), (47, 55, 'FOOD')]})\n",
      "######\n",
      "sentence:  Never put pineapple in your pizza.\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 28\n",
      "end_index: 33\n",
      "[(28, 33, 'FOOD')]\n",
      "word:  pineapple\n",
      "start index: 10\n",
      "end_index: 19\n",
      "[(28, 33, 'FOOD'), (10, 19, 'FOOD')]\n",
      "---------\n",
      "element: ('never put pineapple in your pizza.', {'entities': [(28, 33, 'FOOD'), (10, 19, 'FOOD')]})\n",
      "######\n",
      "sentence:  I would say that pineapple on a pizza could be oltrageous.\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 32\n",
      "end_index: 37\n",
      "[(32, 37, 'FOOD')]\n",
      "word:  pineapple\n",
      "start index: 17\n",
      "end_index: 26\n",
      "[(32, 37, 'FOOD'), (17, 26, 'FOOD')]\n",
      "---------\n",
      "element: ('i would say that pineapple on a pizza could be oltrageous.', {'entities': [(32, 37, 'FOOD'), (17, 26, 'FOOD')]})\n",
      "######\n",
      "sentence:  I miss my mum's risotto!\n",
      "\n",
      "######\n",
      "word:  risotto\n",
      "start index: 16\n",
      "end_index: 23\n",
      "[(16, 23, 'FOOD')]\n",
      "---------\n",
      "element: (\"i miss my mum's risotto!\", {'entities': [(16, 23, 'FOOD')]})\n",
      "######\n",
      "sentence:  Espresso, what else?\n",
      "\n",
      "######\n",
      "word:  espresso\n",
      "start index: 0\n",
      "end_index: 8\n",
      "[(0, 8, 'FOOD')]\n",
      "---------\n",
      "element: ('espresso, what else?', {'entities': [(0, 8, 'FOOD')]})\n",
      "######\n",
      "sentence:  I don't like pizza with pineapple.\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 13\n",
      "end_index: 18\n",
      "[(13, 18, 'FOOD')]\n",
      "word:  pineapple\n",
      "start index: 24\n",
      "end_index: 33\n",
      "[(13, 18, 'FOOD'), (24, 33, 'FOOD')]\n",
      "---------\n",
      "element: (\"i don't like pizza with pineapple.\", {'entities': [(13, 18, 'FOOD'), (24, 33, 'FOOD')]})\n",
      "######\n",
      "sentence:  Never put ketchup salsa in your pasta.\n",
      "\n",
      "######\n",
      "word:  ketchup\n",
      "start index: 10\n",
      "end_index: 17\n",
      "[(10, 17, 'FOOD')]\n",
      "word:  pasta\n",
      "start index: 32\n",
      "end_index: 37\n",
      "[(10, 17, 'FOOD'), (32, 37, 'FOOD')]\n",
      "---------\n",
      "element: ('never put ketchup salsa in your pasta.', {'entities': [(10, 17, 'FOOD'), (32, 37, 'FOOD')]})\n",
      "######\n",
      "sentence:  In heaven, after antipasti, the first course will be pasta.\n",
      "\n",
      "######\n",
      "word:  pasta\n",
      "start index: 53\n",
      "end_index: 58\n",
      "[(53, 58, 'FOOD')]\n",
      "---------\n",
      "element: ('in heaven, after antipasti, the first course will be pasta.', {'entities': [(53, 58, 'FOOD')]})\n",
      "######\n",
      "sentence:  Arrosticini are not kebabs!!!\n",
      "\n",
      "######\n",
      "word:  arrosticini\n",
      "start index: 0\n",
      "end_index: 11\n",
      "[(0, 11, 'FOOD')]\n",
      "---------\n",
      "element: ('arrosticini are not kebabs!!!', {'entities': [(0, 11, 'FOOD')]})\n",
      "######\n",
      "sentence:  Alfredo did not invent any pasta!\n",
      "\n",
      "######\n",
      "word:  pasta\n",
      "start index: 27\n",
      "end_index: 32\n",
      "[(27, 32, 'FOOD')]\n",
      "---------\n",
      "element: ('alfredo did not invent any pasta!', {'entities': [(27, 32, 'FOOD')]})\n",
      "######\n",
      "sentence:  Don't touch my fettuccine.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: (\"don't touch my fettuccine.\", {'entities': []})\n",
      "######\n",
      "sentence:  Hey! Avoid heavy cream and bacon in the carbonara recipe.\n",
      "\n",
      "######\n",
      "word:  carbonara\n",
      "start index: 40\n",
      "end_index: 49\n",
      "[(40, 49, 'FOOD')]\n",
      "word:  heavy cream\n",
      "start index: 11\n",
      "end_index: 22\n",
      "[(40, 49, 'FOOD'), (11, 22, 'FOOD')]\n",
      "---------\n",
      "element: ('hey! avoid heavy cream and bacon in the carbonara recipe.', {'entities': [(40, 49, 'FOOD'), (11, 22, 'FOOD')]})\n",
      "######\n",
      "sentence:  Polenta warms my heart!\n",
      "\n",
      "######\n",
      "word:  polenta\n",
      "start index: 0\n",
      "end_index: 7\n",
      "[(0, 7, 'FOOD')]\n",
      "---------\n",
      "element: ('polenta warms my heart!', {'entities': [(0, 7, 'FOOD')]})\n",
      "######\n",
      "sentence:  TiramisÃ¹ is just the best cake.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('tiramisã¹ is just the best cake.', {'entities': []})\n",
      "######\n",
      "sentence:  All you need is love. But a little chocolate now and then doesn't hurt.\n",
      "\n",
      "######\n",
      "word:  chocolate\n",
      "start index: 35\n",
      "end_index: 44\n",
      "[(35, 44, 'FOOD')]\n",
      "---------\n",
      "element: (\"all you need is love. but a little chocolate now and then doesn't hurt.\", {'entities': [(35, 44, 'FOOD')]})\n",
      "######\n",
      "sentence:  Best Pizza was born in Naples\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 5\n",
      "end_index: 10\n",
      "[(5, 10, 'FOOD')]\n",
      "---------\n",
      "element: ('best pizza was born in naples', {'entities': [(5, 10, 'FOOD')]})\n",
      "######\n",
      "sentence:  I like bucatini all'amatriciana (the real one)\n",
      "\n",
      "######\n",
      "---------\n",
      "element: (\"i like bucatini all'amatriciana (the real one)\", {'entities': []})\n",
      "######\n",
      "sentence:  The Zaza's ApplePie is unmatched\n",
      "\n",
      "######\n",
      "---------\n",
      "element: (\"the zaza's applepie is unmatched\", {'entities': []})\n",
      "######\n",
      "sentence:  Spaghetti \"Bolognese\" does not exist!!!\n",
      "\n",
      "######\n",
      "word:  spaghetti\n",
      "start index: 0\n",
      "end_index: 9\n",
      "[(0, 9, 'FOOD')]\n",
      "---------\n",
      "element: ('spaghetti \"bolognese\" does not exist!!!', {'entities': [(0, 9, 'FOOD')]})\n",
      "######\n",
      "sentence:  Spaghetti bolognese doesnâ€™t exist in Bologna.\n",
      "\n",
      "######\n",
      "word:  spaghetti\n",
      "start index: 0\n",
      "end_index: 9\n",
      "[(0, 9, 'FOOD')]\n",
      "---------\n",
      "element: ('spaghetti bolognese doesnâ€™t exist in bologna.', {'entities': [(0, 9, 'FOOD')]})\n",
      "######\n",
      "sentence:  How could be a world without Fiorentina Steak?\n",
      "\n",
      "######\n",
      "word:  fiorentina steak\n",
      "start index: 29\n",
      "end_index: 45\n",
      "[(29, 45, 'FOOD')]\n",
      "---------\n",
      "element: ('how could be a world without fiorentina steak?', {'entities': [(29, 45, 'FOOD')]})\n",
      "######\n",
      "sentence:  I do love cooking sous vide, but only when I have plenty of time!\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('i do love cooking sous vide, but only when i have plenty of time!', {'entities': []})\n",
      "######\n",
      "sentence:  It's not bistecca unless it's rare.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: (\"it's not bistecca unless it's rare.\", {'entities': []})\n",
      "######\n",
      "sentence:  Pineapple does not belong to pizza.\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 29\n",
      "end_index: 34\n",
      "[(29, 34, 'FOOD')]\n",
      "word:  pineapple\n",
      "start index: 0\n",
      "end_index: 9\n",
      "[(29, 34, 'FOOD'), (0, 9, 'FOOD')]\n",
      "---------\n",
      "element: ('pineapple does not belong to pizza.', {'entities': [(29, 34, 'FOOD'), (0, 9, 'FOOD')]})\n",
      "######\n",
      "sentence:  I love my mouse's lemon cheesecake.\n",
      "\n",
      "######\n",
      "word:  lemon\n",
      "start index: 18\n",
      "end_index: 23\n",
      "[(18, 23, 'FOOD')]\n",
      "---------\n",
      "element: (\"i love my mouse's lemon cheesecake.\", {'entities': [(18, 23, 'FOOD')]})\n",
      "######\n",
      "sentence:  in carbonara, pecorino is used.\n",
      "\n",
      "######\n",
      "word:  carbonara\n",
      "start index: 3\n",
      "end_index: 12\n",
      "[(3, 12, 'FOOD')]\n",
      "word:  pecorino\n",
      "start index: 14\n",
      "end_index: 22\n",
      "[(3, 12, 'FOOD'), (14, 22, 'FOOD')]\n",
      "---------\n",
      "element: ('in carbonara, pecorino is used.', {'entities': [(3, 12, 'FOOD'), (14, 22, 'FOOD')]})\n",
      "######\n",
      "sentence:  Spoiler alert, peperoni are a vegetables types\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('spoiler alert, peperoni are a vegetables types', {'entities': []})\n",
      "######\n",
      "sentence:  Not by bread alone!\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('not by bread alone!', {'entities': []})\n",
      "######\n",
      "sentence:  Get your hands off my pastries\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('get your hands off my pastries', {'entities': []})\n",
      "######\n",
      "sentence:  Take away everything, but not my Nutella\n",
      "\n",
      "######\n",
      "word:  nutella\n",
      "start index: 33\n",
      "end_index: 40\n",
      "[(33, 40, 'FOOD')]\n",
      "---------\n",
      "element: ('take away everything, but not my nutella', {'entities': [(33, 40, 'FOOD')]})\n",
      "######\n",
      "sentence:  Maccherone, you provoked me and now I'll eat you\n",
      "\n",
      "######\n",
      "word:  maccherone\n",
      "start index: 0\n",
      "end_index: 10\n",
      "[(0, 10, 'FOOD')]\n",
      "---------\n",
      "element: (\"maccherone, you provoked me and now i'll eat you\", {'entities': [(0, 10, 'FOOD')]})\n",
      "######\n",
      "sentence:  What more could you want? An amaro Lucano\n",
      "\n",
      "######\n",
      "word:  amaro\n",
      "start index: 29\n",
      "end_index: 34\n",
      "[(29, 34, 'FOOD')]\n",
      "---------\n",
      "element: ('what more could you want? an amaro lucano', {'entities': [(29, 34, 'FOOD')]})\n",
      "######\n",
      "sentence:  First pancake never turns out the best\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('first pancake never turns out the best', {'entities': []})\n",
      "######\n",
      "sentence:  Not all donuts come with a hole\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('not all donuts come with a hole', {'entities': []})\n",
      "######\n",
      "sentence:  A glass of wine a day keeps the doctor away\n",
      "\n",
      "######\n",
      "word:  wine\n",
      "start index: 11\n",
      "end_index: 15\n",
      "[(11, 15, 'FOOD')]\n",
      "---------\n",
      "element: ('a glass of wine a day keeps the doctor away', {'entities': [(11, 15, 'FOOD')]})\n",
      "######\n",
      "sentence:  Good wine makes good blood\n",
      "\n",
      "######\n",
      "word:  wine\n",
      "start index: 5\n",
      "end_index: 9\n",
      "[(5, 9, 'FOOD')]\n",
      "---------\n",
      "element: ('good wine makes good blood', {'entities': [(5, 9, 'FOOD')]})\n",
      "######\n",
      "sentence:  When pigs are butchered, nothing is wasted\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('when pigs are butchered, nothing is wasted', {'entities': []})\n",
      "######\n",
      "sentence:  Don't let the farmer know how good is the pear with the cheese\n",
      "\n",
      "######\n",
      "---------\n",
      "element: (\"don't let the farmer know how good is the pear with the cheese\", {'entities': []})\n",
      "######\n",
      "sentence:  An apple a day keeps the doctor away\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('an apple a day keeps the doctor away', {'entities': []})\n",
      "######\n",
      "sentence:  Whoever has bread does not have teeth and whoever has teeth does not have bread\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('whoever has bread does not have teeth and whoever has teeth does not have bread', {'entities': []})\n",
      "######\n",
      "sentence:  The best pistachio comes from Bronte\n",
      "\n",
      "######\n",
      "word:  pistachio\n",
      "start index: 9\n",
      "end_index: 18\n",
      "[(9, 18, 'FOOD')]\n",
      "---------\n",
      "element: ('the best pistachio comes from bronte', {'entities': [(9, 18, 'FOOD')]})\n",
      "######\n",
      "sentence:  Who doesn't like chocolate has something to hide\n",
      "\n",
      "######\n",
      "word:  chocolate\n",
      "start index: 17\n",
      "end_index: 26\n",
      "[(17, 26, 'FOOD')]\n",
      "---------\n",
      "element: (\"who doesn't like chocolate has something to hide\", {'entities': [(17, 26, 'FOOD')]})\n",
      "######\n",
      "sentence:  Coca-cola, Fanta or Pepsi?\n",
      "\n",
      "######\n",
      "word:  coca-cola\n",
      "start index: 0\n",
      "end_index: 9\n",
      "[(0, 9, 'FOOD')]\n",
      "---------\n",
      "element: ('coca-cola, fanta or pepsi?', {'entities': [(0, 9, 'FOOD')]})\n",
      "######\n",
      "sentence:  If it's not soup, it's wet bread\n",
      "\n",
      "######\n",
      "word:  soup\n",
      "start index: 12\n",
      "end_index: 16\n",
      "[(12, 16, 'FOOD')]\n",
      "---------\n",
      "element: (\"if it's not soup, it's wet bread\", {'entities': [(12, 16, 'FOOD')]})\n",
      "######\n",
      "sentence:  Garlic is good for blood pressure\n",
      "\n",
      "######\n",
      "word:  garlic\n",
      "start index: 0\n",
      "end_index: 6\n",
      "[(0, 6, 'FOOD')]\n",
      "---------\n",
      "element: ('garlic is good for blood pressure', {'entities': [(0, 6, 'FOOD')]})\n",
      "######\n",
      "sentence:  Watermelon contains a lot of water\n",
      "\n",
      "######\n",
      "word:  watermelon\n",
      "start index: 0\n",
      "end_index: 10\n",
      "[(0, 10, 'FOOD')]\n",
      "---------\n",
      "element: ('watermelon contains a lot of water', {'entities': [(0, 10, 'FOOD')]})\n",
      "######\n",
      "sentence:  I have breakfast with a croissant and cappuccino\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('i have breakfast with a croissant and cappuccino', {'entities': []})\n",
      "######\n",
      "sentence:  One cherry leads to the other\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('one cherry leads to the other', {'entities': []})\n",
      "######\n",
      "sentence:  Throw the pasta into a pan full of salted boiling water\n",
      "\n",
      "######\n",
      "word:  pasta\n",
      "start index: 10\n",
      "end_index: 15\n",
      "[(10, 15, 'FOOD')]\n",
      "---------\n",
      "element: ('throw the pasta into a pan full of salted boiling water', {'entities': [(10, 15, 'FOOD')]})\n",
      "######\n",
      "sentence:  Ketchup is not a substitute for tomato sauce\n",
      "\n",
      "######\n",
      "word:  ketchup\n",
      "start index: 0\n",
      "end_index: 7\n",
      "[(0, 7, 'FOOD')]\n",
      "word:  tomato sauce\n",
      "start index: 32\n",
      "end_index: 44\n",
      "[(0, 7, 'FOOD'), (32, 44, 'FOOD')]\n",
      "---------\n",
      "element: ('ketchup is not a substitute for tomato sauce', {'entities': [(0, 7, 'FOOD'), (32, 44, 'FOOD')]})\n",
      "######\n",
      "sentence:  This is the icing on the cake\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('this is the icing on the cake', {'entities': []})\n",
      "######\n",
      "sentence:  Sorrento lemons are famous all over the world\n",
      "\n",
      "######\n",
      "word:  lemon\n",
      "start index: 9\n",
      "end_index: 14\n",
      "[(9, 14, 'FOOD')]\n",
      "---------\n",
      "element: ('sorrento lemons are famous all over the world', {'entities': [(9, 14, 'FOOD')]})\n",
      "######\n",
      "sentence:  When you are sad, the best solution is to eat tiramisu\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('when you are sad, the best solution is to eat tiramisu', {'entities': []})\n",
      "######\n",
      "sentence:  In carbonara, bacon is not used, but pig cheek\n",
      "\n",
      "######\n",
      "word:  carbonara\n",
      "start index: 3\n",
      "end_index: 12\n",
      "[(3, 12, 'FOOD')]\n",
      "---------\n",
      "element: ('in carbonara, bacon is not used, but pig cheek', {'entities': [(3, 12, 'FOOD')]})\n",
      "######\n",
      "sentence:  Strawberries and cream are a winning team\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('strawberries and cream are a winning team', {'entities': []})\n",
      "######\n",
      "sentence:  Pizza margherita is the most famous in the world\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 0\n",
      "end_index: 5\n",
      "[(0, 5, 'FOOD')]\n",
      "---------\n",
      "element: ('pizza margherita is the most famous in the world', {'entities': [(0, 5, 'FOOD')]})\n",
      "######\n",
      "sentence:  All you need is ~love~ Coffee\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('all you need is ~love~ coffee', {'entities': []})\n",
      "######\n",
      "sentence:  Bread and jam from snack\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('bread and jam from snack', {'entities': []})\n",
      "######\n",
      "sentence:  You never give up on ice cream.\n",
      "\n",
      "######\n",
      "word:  ice cream\n",
      "start index: 21\n",
      "end_index: 30\n",
      "[(21, 30, 'FOOD')]\n",
      "---------\n",
      "element: ('you never give up on ice cream.', {'entities': [(21, 30, 'FOOD')]})\n",
      "######\n",
      "sentence:  Life is like a barbecue. There is always someone sweating all day for others to sit and eat.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('life is like a barbecue. there is always someone sweating all day for others to sit and eat.', {'entities': []})\n",
      "######\n",
      "sentence:  There is nothing that can't be solved with a smile and a good meal.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: (\"there is nothing that can't be solved with a smile and a good meal.\", {'entities': []})\n",
      "######\n",
      "sentence:  Those who only drink water have a secret to hide.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('those who only drink water have a secret to hide.', {'entities': []})\n",
      "######\n",
      "sentence:  Love without a kiss is like pizza without cheese.\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 28\n",
      "end_index: 33\n",
      "[(28, 33, 'FOOD')]\n",
      "---------\n",
      "element: ('love without a kiss is like pizza without cheese.', {'entities': [(28, 33, 'FOOD')]})\n",
      "######\n",
      "sentence:  A circle cut into triangles, inside a square: Pizza is the nirvana of Pythagoras!\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 46\n",
      "end_index: 51\n",
      "[(46, 51, 'FOOD')]\n",
      "---------\n",
      "element: ('a circle cut into triangles, inside a square: pizza is the nirvana of pythagoras!', {'entities': [(46, 51, 'FOOD')]})\n",
      "######\n",
      "sentence:  Fatte 'na pizza c'a pummarola 'ncoppa, vedrai che il mondo poi ti sorriderÃ .\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 10\n",
      "end_index: 15\n",
      "[(10, 15, 'FOOD')]\n",
      "---------\n",
      "element: (\"fatte 'na pizza c'a pummarola 'ncoppa, vedrai che il mondo poi ti sorriderã\\xa0.\", {'entities': [(10, 15, 'FOOD')]})\n",
      "######\n",
      "sentence:  When the moon hits your eye like a big pizza pie, that's amore!\n",
      "\n",
      "######\n",
      "word:  pizza\n",
      "start index: 39\n",
      "end_index: 44\n",
      "[(39, 44, 'FOOD')]\n",
      "---------\n",
      "element: (\"when the moon hits your eye like a big pizza pie, that's amore!\", {'entities': [(39, 44, 'FOOD')]})\n",
      "######\n",
      "sentence:  You say that beauty will save the world because you have not tasted the Neapolitan Pastiera.\n",
      "\n",
      "######\n",
      "word:  pastiera\n",
      "start index: 83\n",
      "end_index: 91\n",
      "[(83, 91, 'FOOD')]\n",
      "---------\n",
      "element: ('you say that beauty will save the world because you have not tasted the neapolitan pastiera.', {'entities': [(83, 91, 'FOOD')]})\n",
      "######\n",
      "sentence:  The best way not to have unpleasant smells in the kitchen: eat out.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('the best way not to have unpleasant smells in the kitchen: eat out.', {'entities': []})\n",
      "######\n",
      "sentence:  I went to a Bio restaurant and the waiter told me all about his life.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('i went to a bio restaurant and the waiter told me all about his life.', {'entities': []})\n",
      "######\n",
      "sentence:  There is more complicity between me and the Nutella than between certain couples at the restaurant fixed on their cell phones.\n",
      "\n",
      "######\n",
      "word:  nutella\n",
      "start index: 44\n",
      "end_index: 51\n",
      "[(44, 51, 'FOOD')]\n",
      "---------\n",
      "element: ('there is more complicity between me and the nutella than between certain couples at the restaurant fixed on their cell phones.', {'entities': [(44, 51, 'FOOD')]})\n",
      "######\n",
      "sentence:  In the United States the food is really bad. In some restaurants they even bring you the prognosis with the bill.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('in the united states the food is really bad. in some restaurants they even bring you the prognosis with the bill.', {'entities': []})\n",
      "######\n",
      "sentence:  Two beers or not two beers: that is the passion.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('two beers or not two beers: that is the passion.', {'entities': []})\n",
      "######\n",
      "sentence:  How can you have fun at a party where the beers are warm and the women are cold?\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('how can you have fun at a party where the beers are warm and the women are cold?', {'entities': []})\n",
      "######\n",
      "sentence:  24 hours in a day, 24 beers in a box. Coincidence?\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('24 hours in a day, 24 beers in a box. coincidence?', {'entities': []})\n",
      "######\n",
      "sentence:  Drinking non-alcoholic beer is like listening a porn movie on the radio.\n",
      "\n",
      "######\n",
      "---------\n",
      "element: ('drinking non-alcoholic beer is like listening a porn movie on the radio.', {'entities': []})\n",
      "######\n",
      "sentence:  Jesus turned water into wine. No wonder twelve disciples followed him everywhere.\n",
      "\n",
      "######\n",
      "word:  wine\n",
      "start index: 24\n",
      "end_index: 28\n",
      "[(24, 28, 'FOOD')]\n",
      "---------\n",
      "element: ('jesus turned water into wine. no wonder twelve disciples followed him everywhere.', {'entities': [(24, 28, 'FOOD')]})\n",
      "######\n",
      "sentence:  Those who don't like wine, God take away the water.\n",
      "\n",
      "######\n",
      "word:  wine\n",
      "start index: 21\n",
      "end_index: 25\n",
      "[(21, 25, 'FOOD')]\n",
      "---------\n",
      "element: (\"those who don't like wine, god take away the water.\", {'entities': [(21, 25, 'FOOD')]})\n",
      "######\n",
      "sentence:  Reality is an illusion that occurs because of the lack of wine.\n",
      "\n",
      "######\n",
      "word:  wine\n",
      "start index: 58\n",
      "end_index: 62\n",
      "[(58, 62, 'FOOD')]\n",
      "---------\n",
      "element: ('reality is an illusion that occurs because of the lack of wine.', {'entities': [(58, 62, 'FOOD')]})\n",
      "######\n",
      "sentence:  The best thing about wine is that, for two hours, your problems are someone else's.\n",
      "######\n",
      "word:  wine\n",
      "start index: 21\n",
      "end_index: 25\n",
      "[(21, 25, 'FOOD')]\n",
      "---------\n",
      "element: (\"the best thing about wine is that, for two hours, your problems are someone else's.\", {'entities': [(21, 25, 'FOOD')]})\n",
      "Iteration #0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"sorrento lemons are famous all over the world\" with entities \"[(9, 14, 'FOOD')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Losses: {'ner': 114.21813420570001}\n",
      "Iteration #1\n",
      "Losses: {'ner': 27.827309145802893}\n",
      "Iteration #2\n",
      "Losses: {'ner': 13.01394680175964}\n",
      "Iteration #3\n",
      "Losses: {'ner': 14.751587433780923}\n",
      "Iteration #4\n",
      "Losses: {'ner': 9.271102502738033}\n",
      "Iteration #5\n",
      "Losses: {'ner': 3.470370844055254}\n",
      "Iteration #6\n",
      "Losses: {'ner': 1.9909903041708936}\n",
      "Iteration #7\n",
      "Losses: {'ner': 1.893550522722221}\n",
      "Iteration #8\n",
      "Losses: {'ner': 2.259878548340071}\n",
      "Iteration #9\n",
      "Losses: {'ner': 0.584652367390258}\n",
      "Saved correctly\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# for _,annotations in train_data:\r\n",
    "#     for ent in annotations.get('entities'):/\r\n",
    "        # print(ent)\r\n",
    "#     for ent in annotations.get('entities:'):\r\n",
    "#         ner.add_label(ent[2])\r\n",
    "# train_data\r\n",
    "# for _,annotations in train_data:\r\n",
    "#     for ent in annotations.get('entities'):\r\n",
    "#         print(ent)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# for _,annotations in train_data:\r\n",
    "#     for ent in annotations.get('entities'):\r\n",
    "#         # if ent == ():\r\n",
    "#             raise TypeError\r\n",
    "#         print(ent)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# STEP 3 - TEST THE UPDATED MODEL\r\n",
    "print('Loading model....')\r\n",
    "# Load updated model\r\n",
    "nlp_updated = spacy.load(output_dir)\r\n",
    "\r\n",
    "doc =nlp_updated(\"I don't like pizza with pineapple.\")\r\n",
    "# TBD: test with a old sentence\r\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])\r\n",
    "\r\n",
    "# TBD: test with a new sentence and an old brand\r\n",
    "doc =nlp_updated(\"in carbonara, parmigiano is not used.\")\r\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])\r\n",
    "# TBD: test with a new sentence and a new brand\r\n",
    "doc =nlp_updated(\"Fabio likes full-stack development\")\r\n",
    "print(\"entities:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading model....\n",
      "entities: [('pizza', 'FOOD'), ('pineapple', 'FOOD')]\n",
      "entities: [('carbonara', 'FOOD')]\n",
      "entities: [('Fabio', 'FOOD')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "tup = ()\r\n",
    "if tup == ():\r\n",
    "    print(tup)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('strive': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "f5610a57ce5a66969d95506b8c0c9e3b70160de2f7592df689878f178730b779"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}